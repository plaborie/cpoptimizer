\documentclass{ecai2014}
\usepackage{times}
%\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{nicefrac}
\usepackage{helvet}
\usepackage{courier}
\usepackage{amsmath,amssymb}
\usepackage[pdftex]{graphicx}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
%\usepackage{algpseudocode}
\usepackage[usenames]{color}
\usepackage{theomac}

\newcommand{\Z}{\mathbb{Z}}

\newtheorem{definition}{Definition}
\newtheoremWithMacro{property}{Property}
\def\qed{\hfill \quad \vrule height4.17pt width4.17pt depth0pt} 
\newenvironment{proof}[1][Proof]{\noindent \textbf{#1:} }{\qed}

% Macro for colored "todo" notes:
\definecolor{NoteColor}{rgb}{1, 0.2, 0.2}
\newcommand{\note}[1]{\textcolor{NoteColor}{#1}}

% Macros for math functions:
\DeclareMathOperator{\pos}{pos}
\DeclareMathOperator{\idx}{index}

\newcommand{\algn}{\text{\it algn}}

%%\ecaisubmission   % inserts page numbers. Use only for submission of paper.
                  % Do NOT use for camera-ready version of paper.

\begin{document}

\title{An Optimal Iterative Algorithm for Extracting MUCs\\ in a Black-box Constraint Network}

\author{Philippe Laborie\institute{IBM Software Group,
France, email: laborie@fr.ibm.com} }

\maketitle
\bibliographystyle{ecai2014}

\begin{abstract}
We present a non-intrusive iterative algorithm for extracting Minimal Unsatisfiable Cores in black-box constraint networks. The problem can be generalized as the one of finding a minimal subset satisfying an upward-closed property ${\cal P}$. If performance is measured as the number of infeasibility property checks, we show that the proposed algorithm, ADEL, is optimal both for small and for large MUCs and that it consistently outperforms existing approaches in between those two extremal cases.
\end{abstract}

\section{Introduction}

When a Constraint Satisfaction Problem is infeasible, providing a minimal explanation for infeasibility in the form of a minimal subset of constraints that are mutually contradictory (known as Minimal Unsatisfiable Core or MUC) helps identifying the causes of the infeasibility \cite{Chinneck2007}. Many existing approaches for MUC extraction exploit the particular features of the problem or of the resolution engine. For instance techniques such as {\em elastic filters} can be used for LP models \cite{Chinneck1997}, {\em explanations} recording for CP models \cite{Jussien2002} or {\em no-goods} learning for SAT models \cite{MarquesSilva1996}. In this paper, we tackle the problem of MUC extraction in a {\em non-intrusive} way with respect to the resolution engine by considering that checking for the (in)feasibility of a subset of constraints is a {\em black-box} operation. Advances of the state-of-the-art in Optimization result in increasingly sophisticated and efficient engines. Engines sophistication makes it harder to implement intrusive methods to compute MUCs whereas increase of engines efficiency makes infeasibility property checks faster. Both aspects tend to make the black-box approach attractive. The problem studied in this paper is thus more general than MUC extraction and can be defined as follows: given a finite set $U$ and a property ${\cal P}$ on the subsets of $U$ that is upward-closed (that is, whenever it holds for a subset $X$ it also holds for any superset of $X$), find a {\em minimal subset} of $U$ that satisfies property ${\cal P}$. For MUC extraction the property ${\cal P}(X)$ is the {\em infeasibility} of a subset of constraints $X$, it clearly is upward-closed as the superset of any infeasible subset of constraints is infeasible too. The works closest to ours are the {\tt QuickXplain} recursive algorithm \cite{Junker2004} developed in the context of MUC extraction for constraint programming using a black-box approach and the iterative dichotomy algorithm {\tt DC} proposed in \cite{Hemery2006}. After introducing some notations and formally defining the problem, we describe the proposed algorithm {\tt ADEL} (standing for the four ingredients of the approach: Acceleration, Dichotomy, Estimation and Lazy checks). Last section reports some performance results showing that the complexity of ADEL is optimal both for small and large minimal subsets and that it outperforms both the {\tt QuickXplain} and the {\tt DC} algorithms. 

% ===============================================================
% PROBLEM DEFINITION AND NOTATIONS
% ===============================================================

\section{Problem Definition and Notations}

Let $U$ be a finite set of cardinality $n$ and ${\cal P}$ an {\em upward-closed} property on its powerset $2^U$ that is, a property such that: \linebreak $\big( X \subseteq Y \subseteq U \big) \land {\cal P}(X) \Rightarrow {\cal P}(Y)$.

\begin{definition}[Minimal Subset]
\label{minsubset}
A subset $X \subseteq U$ is said to be {\bf minimal} if and only if:
${\cal P}(X) \land \forall Y \subset X: \neg {\cal P}(Y)$.
\end{definition}

In the sequel of this paper we assume ${\cal P}(U)$ that is, there exist at least one minimal subset. Without loss of generality we assume a total order over the elements in $U$ so that the elements can be indexed: $U=(u_1,...,u_n)$. For $1 \leq i$, \smash{$U_{i\rightarrow}$} denotes the subset \smash{$\{u_j | i \leq j \leq n \}$} of all $u_j$ with index $j$ greater than or equal to $i$ (note that if $i>n$, then \smash{$U_{i\rightarrow}=\emptyset$}).

The problem studied in this paper is the design of an efficient algorithm to compute a minimal subset $X$ without any knowledge about property ${\cal P}$ beside the assumption that it is upward-closed. We estimate the complexity of an algorithm as the number of property checks it performs. Note that for comparing the different algorithms we use in this paper a more fine-grain measure than the traditional {\em big O} comparison because we count the number of property checks which is an homogeneous measure for all the approaches. That's why we use a comparison {\em on the order of}: $f(n) \sim g(n)$ meaning $\lim_{n\rightarrow+\infty} \big( f(n)/g(n) \big) = 1$. This allows constant factors to be taken into account.

% ===============================================================
% ALGORITHM
% ===============================================================

\section{ADEL Algorithm}

We now describe the ADEL algorithm for computing a minimal subset. The input problem is given by: (1) the finite set $U=(u_1,...,u_n)$ and (2) the upward-closed property ${\cal P}$. The input set $U$ is stored as an array of size $n$ where $U[i]=u_i, i \in \{1,...,n\}$. 

In Algorithm \ref{alg:ADEL1}, at line 1, the array $U$ is shuffled. This will rule out any particular structure in the set $U$ and, informally speaking, will ensure that minimal subsets are uniformly distributed in $U$. Procedure $\mathrm{FindNext}(X,U,i,{\cal P},s)$ is in charge of finding and returning the largest index $j$ ($i \leq j$) such that ${\cal P}(X \cup U_{j \rightarrow})$. 

The ideas of {\em acceleration} and {\em dichotomy} exploited in the $\mathrm{FindNext}$ function in Algorithm \ref{alg:ADEL2} rely on the fact that the index $j$ returned by this procedure is likely to be quite close to index $i$. This is of course especially true if the size of the selected minimal subset is large. So it generally pays off to search for such an index $j$ starting from index $i$ with an acceleration phase (trying $i+s$, $i+2s$, $i+4s$, ..., $i+2^ks$) until the first index such that $\neg {\cal P}(X \cup U_{{i+2^ks} \rightarrow})$ and then applying a dichotomic search on the index segment $[i+2^{k-1}s,i+2^ks)$. We can elaborate further on this idea by learning the initial step $s$ of the acceleration phase from the previous calls to the $\mathrm{FindNext}$ procedure. Indeed, as the initial set $U$ has been shuffled we can expect the probability distribution of the distances between consecutive elements of $X$ not to depend much on which element is considered, thus this information can be estimated from the previous elements. In this context, the initial value of $s$ represents the expected average distance between two successive elements of the selected minimal subset. For the first call to $\mathrm{FindNext}$, we take $s=n$ so this first call boils down to the pure dichotomy algorithm. For the later calls, the initial $s$ is computed as the average of the distance between successive elements already added to the minimal set $X$ under construction.

When the selected minimal subset is small, it's worth to check property ${\cal{P}}$ on the current subset $X$ each time a new element $u_i$ is added. But when the minimal subset is large, with a size typically getting close to $n$, this may represent a large proportion of the property checks of the algorithm. On the other side, it is not necessary to stop the algorithm as soon as one has proved the current subset $X$ satisfies the property: one can let function $\mathrm{FindNext}$ show that the current subset does not have to be extended. It will show it with approximately $\log_2(n)$ property checks in the acceleration step. So we consider that once the size of the current subset $X$ is larger than $\log_2(n)$, as the effort to be spent for proving the property for the selected minimal subset with function $\mathrm{FindNext}$ won't exceed the effort already spent checking the property for each elements added to $X$ so far, we can stop checking the property in Algorithm \ref{alg:ADEL1}, line $13$. This is the idea of {\em lazy checks}.

\begin{algorithm}
	\caption{ADEL($U$, ${\cal P}$)}
	\label{alg:ADEL1}
	\begin{algorithmic}[1]
    \Require ${\cal P}(U)$
		\State $\mathrm{Shuffle}(U)$ \Comment{Called once: $O(n)$}
		\State $X \gets \emptyset$ \Comment{$X$: minimal subset under construction}
		\State $i \gets 0$ \Comment{$i$: index of last element added to $X$}
		\State $s \gets n$, $d_1 \gets 0$, $d_0 \gets 0$
		\Loop
			\State $j \gets$ FindNext$(X,U,i+1,{\cal P},s)$
			\If {$j > n$} \Comment{Last acceleration showed ${\cal P}(X)$ holds}
			\State \textbf{return} $X$
			\EndIf
			\State $d_0 \gets d_0 + 1$
			%\State $d_1 \gets d_1 + j - i$, $s_0 = \lfloor d_1 / d_0 \rfloor - 1$
			% I DON'T THINK THE -1 ABOVE IS RIGHT, WITH IT WE CAN HAVE s0=0
			\State $d_1 \gets d_1 + j - i$, $s = \lfloor d_1 / d_0 \rfloor$ \Comment{Distance Estimation}
			\State $i \gets j$
			\State $X \gets X \cup \{ U[i] \}$
		\If{$i \leq \log_2(n) \land {\cal P}(X)$} \Comment{Lazy check}
		\State  \textbf{return} $X$
		\EndIf
		\EndLoop
		%\EndProcedure
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}
	\caption{FindNext($X$, $U$, $i$, ${\cal P}$,$s$)}
	\label{alg:ADEL2}
	\begin{algorithmic}[1]
	\Require{${\cal P}(X \cup U_{i \rightarrow})$}
	\State $l \gets i$, $r \gets n$
	\While {$(l \leq n) \land {\cal P}(X \cup U_{{i+s} \rightarrow})$} \Comment{Accelerate}
	\State $l \gets i+s$, $s \gets s*2$
	\EndWhile
	\If {$l>n$} 
	\State \textbf{return} $l$ \Comment{Acceleration showed ${\cal P}(X)$ holds}
	\Else
	\State $r \gets i+s-1$
	\EndIf
	  \While {$l \neq r$} \Comment{Dichotomize}
	    \State $m \gets \lceil (l+r)/2 \rceil$
	    \If {${\cal P}(X \cup U_{m \rightarrow})$} 
	      \State $l \gets m$
	    \Else
	      \State $r \gets m-1$
	    \EndIf
	  \EndWhile
		\State \textbf{return} $l$
	\end{algorithmic}
\end{algorithm}
% ===============================================================
% EXPERIMENTAL STUDY
% ===============================================================


\section{Performance Study}

A complexity study of ADEL as well as some experiments not reported here by lack of space show that:
\begin{itemize}
\item it is {\em optimal} for small subsets, with a complexity in the order of $\log_2(n)$ for a unique minimal subset of size $1$.
\item it is {\em optimal} for large subsets, with a complexity in the order of $n$ for a minimal subset of size $n$.
\item the average number of checks behaves continuously in between those two extremal cases and outperforms all variants of the ADEL algorithm obtained by switching off any of its features (acceleration, distance estimation, lazy checks).
\item in the case of a unique minimal subset of size one, it performs in average \nicefrac{3}{2} times less checks than the recursive {\tt QuickXplain} algorithm \cite{Junker2004} (33\% less checks).
\item in the case of a unique minimal subset of size $n$, for large values of $n$, it performs about twice less checks than the {\tt QuickXplain} algorithm (50\% less checks).
\item in the case of a unique minimal subset of size $n$, for large values of $n$  it performs about $\log_2(n)$ times less checks than the {\tt DC} algorithm that implements a pure dichotomical search \cite{Hemery2006}.
\item in between those two extremal cases it consistently performs less property checks than the {\tt QuickXplain} algorithm (between 10\% and 50\% less checks in the instances generated for our experiments).
\end{itemize} 

\section{Conclusion}
This paper tackles the problem of finding a minimal subset satisfying an upward-closed property. No other assumption is made about the property being checked and the objective is to minimize the number of checks. The approach can be applied to the extraction of MUCs in Constraint Networks. The proposed {\tt ADEL} algorithm initially shuffles the set of elements and then exploits the probabilistic properties of the position of consecutive elements in the selected subset. The algorithm is shown to be optimal on both extreme cases with minimal subsets of size $1$ and $n$ and to perform less property checks than existing {\tt DC} and {\tt QuickXplain} approaches. An additional interest of ADEL relies on the fact it is by nature an iterative algorithm and is thus easier to implement than a recursive one like {\tt QuickXplain} if recursion is to be avoided.
Algorithm {\tt ADEL} is used as the implementation of the MUC extraction functionality (Conflict Refiner) in IBM ILOG CP Optimizer since version 12.5.

\bibliography{ECAI-224}
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
