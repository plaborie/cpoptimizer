Le papier décrit l'utilisation du planificateur FF afin de guider
l'apprentissage du planificateur probabiliste FPG.

Le papier reprend l'essentiel de la description du planificateur FPG
(Buffet&Aberdeen 2006) et, après avoir rappelé les principes généraux
de FF, décrit l'utilisation de ce dernier pour guider l'apprentissage
de FPG.

Bien que l'architecture générale du papier semble judicieuse, il est
plutôt difficile à lire car les différentes parties manquent de
liaison et/ou font de nombreux présupposés.

En particulier, la section 3 (IS for OLPomdp: Theory) n'explique pas
clairement ce que sont les distributions p et q dans le contexte de
OLPomdp (sauf dans un texte entre parenthèses ou l'on devine que q ==
the teacher's policy). Le détail de l'utilisation de techniques
d'importance sampling pour biaiser l'apprentissage en utilisant FF
n'est donc pas clair.

Dans la description de FPG en Section 2, il n'est pas dit comment le
poids de chaque action f_i(s_t,theta_i) est calcule. Ici encore, il
faut lire entre les lignes (et les parenthèses) pour voir qu'il s'agit
d'un perceptron.

En section 4, est-ce que epsilon = 1 revient au simple planificateur
FF ? Cela semblerait être le cas mais on peut avoir un doute en lisant
la section 5.

La figure 2 mériterait d'être mieux décrite ou bien omise car en
l'état actuel des commentaires elle n'est pas informative.

Quelques coquilles:
- p2, "in a machine learning context; with advanced": ";"
- p6, il manque une série d'espaces dans "FF,FPGand libPG(the ...)"

Malgré le manque de clarté du papier, je pense que l'idée d'utiliser
un planificateur déterministe pour guider l'apprentissage de FPG est
intéressante et est une bonne voie de recherche à encourager c'est
pourquoi j'aurais tendance à accepter le papier.

