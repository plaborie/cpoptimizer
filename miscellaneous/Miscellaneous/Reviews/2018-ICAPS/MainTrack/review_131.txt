Title:	Mode List vs Activity List Representation for the Multi-mode Resource Constrained Project Scheduling Problem

Evaluation

Significance (*). Does the paper contribute a major breakthrough or an incremental advance?
 3: substantial contribution or strong impact
*2: modest contribution or average impact
 1: minimal contribution or weak impact
 
Soundness (*). Is the technical development accurate?
 3: correct
*2: minor inconsistencies or small fixable errors
 1: major errors
 
Scholarship (*). Please provide a scholarship score.
 3: excellent coverage of related work
*2: relevant literature cited but could be expanded
 1: important related work missing, or mischaracterizes prior research
 
Clarity (*). Please provide a clarity score.
 3: well written
*2: mostly readable with some room for improvement
 1: hard to follow
 
Reproducibility (*). Please provide a reproducibility score.
 5: code and domains (whichever apply) are already publicly available
 4: authors promise to release code and domains (whichever apply)
 3: authors describe the implementation and domains in sufficient detail
*2: some details missing but still appears to be replicable with some effort
 1: difficult to reproduce because of missing detail
 
Overall evaluation (*). Please provide an overall score.
  3: strong accept
  2: accept
* 1: weak accept
*-1: weak reject
 -2: reject
 -3: strong reject
 
Reviewer's confidence (*). Reviewer's confidence
 4: expert
*3: high
 2: medium
 1: low
 
Suitable for a demo? (*). Suitable for a demo?
 3: yes
 2: maybe
*1: no
 
Nominate for Best Paper Award (*). Nominate for Best Paper Award
 2: yes
*1: no
 
Nominate for Best Student Paper Award (if eligible) (*). Nominate for Best Student Paper Award (if eligible)
 2: yes
*1: no

Additional scores

[Applications track ONLY]: Importance and novelty of the application (*). [Applications track ONLY]: Importance and novelty of the application
 6: N/A (not an Applications track paper)
 5: very significant - approach and/or application are new and important
 4: novel - approach and/or application are new but not so important
 3: moderate - moderate significance of approach and/or application
 2: marginal - parts of the application or approach are new
 1: none - similar approach to the same application has been used before
 
[Applications track ONLY]: Importance of planning/scheduling technology to the solution of the problem (*). [Applications track ONLY]: Importance of planning/scheduling technology to the solution of the problem
 5: N/A (not an Applications track paper)
 4: very important - essential to solving the problem
 3: moderately important - adds significant capabilities
 2: marginally important - improves usability, capabilities or performance
 1: not important - could be done without it
 
[Applications track ONLY] Maturity (*). [Applications track ONLY] Maturity.
 7: N/A (not an Applications track paper)
 6: study of the success, acceptance, impact and/or deficiencies of a fielded system
 5: fielded system
 4: mature system with testing on realistic problems
 3: early prototype system with testing on realistic problems
 2: early prototype system with testing on artificial data
 1: challenge problem
 
[Robotics track ONLY]: Balance of Robotics and Automated Planning and Scheduling (*). [Robotics track ONLY]: Balance of Robotics and Automated Planning and Scheduling
 6: N/A (not a Robotics track paper)
 5: excellent mix between the two fields
 4: good mix between the two fields
 3: fair mix between the two fields
 2: nothing Robotics specific, pure "classical" ICAPS paper
 1: nothing on Automated Planning, pure Robotics paper
 
[Robotics Track ONLY]: Evaluation on physical platforms/simulators (*). [Robotics Track ONLY]: Evaluation on physical platforms/simulators
 6: N/A (not a Robotics track paper)
 5: runs on real robots
 4: runs in a standard robot simulator (Gazebo, Morse etc.)
 3: could be used with a simulator or robot system
 2: still some work to have it running on robots
 1: cannot run on a real or simulated robot system in its current form
 
[Robotics Track ONLY]: Significance of the contribution (*). [Robotics Track ONLY]: Significance of the contribution
 6: N/A (not a Robotics track paper)
 5: significant in both Robotics and Planning
 4: significant in Planning (i.e. planning researchers would care about this paper)
 3: significant in Robotics (i.e. robotics researchers would care about this paper)
 2: marginally significant in one Robotics and/or Planning
 1: not significant


Review

Review (*). 
Please provide a detailed review, including justification for your scores. This review will be sent to the authors unless the PC chairs decide not to do so.

The article is an extension of the one published in COPLAS-2017. The principal extension is a comparison of the proposed Genetic Algorithm with a CP approach using CP Optimizer.

The idea of using model-list representations to focus the search on execution modes is very interesting and the reported results seems promising. 

The paper is in general well written but in could be improved in a few places (see below).

As you are comparing the GA against a CP approach (CP Optimizer) in the experimental section, I think that CP approaches should be mentioned in the literature review, even if they are more generic than the particular problem treated in the paper.

My main concern is that it is never completely clear in the paper how the two approaches (mode lists and activity lists) are articulated. It is clear that, in order to produce a schedule one needs to decode BOTH the mode list AND the activity list. So the size of the search space for the indirect representation is the cartesian product of both representations (that is, in m^n * n!) and from this point of view, I find Figure 4 difficult to interpret as the figure seems to suggest that the two representations address the same solution space. There is the same ambiguity when comparing the redundancy between the 2 representations in section 6.1: Given that the search on the mode-list does not "invent" new activity permutations and so only works with the permutations present in the initial population (which, a priori, only represents a tiny part of the n! possible ones), it seems that the mode-list search only explores a very small part of the search space. This may be justified by the fact many (most) of the permutations are redundant and lead to the same schedule (but then, most of the activity lists in the initial population too) and that the "noise" added by the mode changes (by changing the duration of the activities) allows covering reasonably well the set of schedules, but still, this is not really convincing. 

Still on the same topic, Figure 6 shows the number of "unique" and "redundant" solutions for the different instances. But it is not clear how these numbers are computed with respect to the mode lists. Which mode lists are considered for decoding the n! activity lists and assess the redundancy of solutions? Also, as far as I understand, a solution (activity list) is unique if and only if all the other activity lists (with which mode-list?) are decoded to a different schedule. I'm not sure the distinction between unique and redundant activity lists is very relevant (some activity lists may be "almost" unique, for instance if the schedule only corresponds to 2 activity lists, while others may be much more redundant). It seems that a more interesting indicator of the redundancy of a representation would be ratio between the number of different activity lists and the number of different schedules after decoding. And all this depends a lot on the structure of the instances. For instance if you suppose a single resource of capacity 1 and no precedence constraints then there is no redundancy in the activity list representation as it can be considered as a direct representation of the schedule. I'm wondering to which extent, some of the conclusions about the redundancy are related with the particular characteristics of the instances in the benchmark (density and topology of precedence constraints, variability of the energy cost/duration for each mode of an activity that could give a very big importance to the mode selection compared to the importance of where the activity is scheduled, ...). There is of course a similar remark for the study on Figure 7 where it is not clear which activity lists are used when decoding the complete set of mode lists.

I think some clarifications along these questions should be provided in the rebuttal.

Concerning the comparison with the CP approach in section 6.2, at first sight, a 10s time limit seems quite small to compare the 2 approaches. Did you try a longer time limit? Does it impact the results?

I think some information about the computation times should also be provided on Table 1. In particular it makes it difficult to relate it with Table 2. It would probably be a good idea to provide the comparison on Table 2 for different time limits, just like done on Table 1 for different number of iterations.

On Table 2 you mention the number of optimal solutions. I suppose that, as the GA cannot make a proof, it is just a measure of how many times the different approaches found an optimal solution (independently of the proving that it is optimal). How did you compute optimality proofs? By using CP Optimizer? If yes, it could be interesting to increase the focus of CP Optimizer on optimality proofs (by using a value close to the number of parallel workers for search parameter FailureDirectSearchEmphasis, like using 3.5 if the number of parallel workers is 4 for instance). 



Confidential remarks for the program committee. If you wish to add any remarks intended only for PC members, please write them below. These remarks will only be seen by the PC members having access to reviews for this submission. They will not be sent to the authors. This field is optional.


