
Title:	 Self-Improvement through Self-Understanding
Authors: J. William Murdock, Ashok K. Goel


1. confidential comments to the editor
--------------------------------------

My review should be moderated by the fact I'm not an expert in many of
the domains touched by the paper such as Cased-Based Planning, Machine
Learning, Meta-Reasoning and Agent Modelling.

2. overall evaluation of the paper
--------------------------------------

Reject.


3. comments to the authors. 
--------------------------------------

Overall comments
-------------------------------

My principal overall comment is that the paper seems to lack some real
focus. It seems to constantly hesitate between two (equally important)
types of content: either a high-level description of the complete REM
framework or, as claimed in the introduction, a real focus on the
proactive relation mapping approach. The result is that, after reading
the paper, one only gets a superficial understanding of both contents. 

In the study, proactive relation mapping is limited to task connection
using a single known relation (inversion, generalisation or
specialisation). It is mainly illustrated on the disassembly/assembly
example in ADDAM for the inversion relation. It sounds like for this
domain, the relation mapping works reasonably well because:
(1) the inversions that are used (action type inversion + temporal
constraints inversion) are relevant to the pair new task/known task
(assembly/disassembly), and 
(2) some kind of problems that may happen when doing inversion
(related with the fact inversion is not idempotent) seems to be
"hard-coded" in the algorithm for relation mapping so as to ensure
that, at least the Q-learning will be able to find a solution. This is
ensured by keeping the original task together with the reversed one
as an alternative.

It is not evident that this still would work in another domain. For
item (1), there could be many very different semantics associated with
the relation "inverse-of" that depends on the context (e.g. for the
addition, -2 may be considered as the inverse-of 2, for the
multiplication, that would be 0.5). I guess determining this
inverse-of relation may be a real issue for the designers of the
model. Item (2) is also related to this: in the assembly/disassembly
example, it turns out that the temporal relations between actions
needs to be reversed when transforming a disassembly plan into an
assembly one. But this may absolutely not be the case in other
domains. Suppose for instance a slight variant (maybe not very
realistic but this is just for the illustration) of the
assembly/disassembly domain where components are glued together
instead of being assembled with screws. Now suppose you have 4 basic
actions: glue (inverse_of: dissolve), stick_together (inverse_of:
separate). A plan for disassembling objects will be:
dissolve->separate whereas a plan for assembling would be:
glue->stick_together. In this case, actions types needs to be reversed
but not the precedence constraints. I'm just wondering how the
proposed approach would help in this case. 

Although it seems to be used in the logistics and the web browser
experiments, no detailed example is given about proactive relation
mapping using generalisation or specialisation and the issues it
raises.


Detailed comments
-------------------------------

In the introduction the definition of the input task as well as the
frontier between input task and input values could be better
precised. Is the input task only a general task identifier known in
the model (e.g. "disassembly", which would mean that in the classical
ADDAM application, there is only one possible input task) or can it be
a partially specified task described in TMKL?

The term of "execution" is extensively used in the article and many
times one wonders if it means an actual execution of the tasks in the
environment (in this case, failures may be due to some
non-deterministic events not present in the model) or just some kind
of simulation of the execution of the tasks using their execution
model so as to perform learning based on the task model only.

The description of fixed-value production is really not clear, neither
in the introduction, neither in the dedicated section 5.3. 

In the example of task in TMKL on Table 1, I was surprised not to find
any reference to the device the component is removed from. Is it a
simplification?

As already mentioned in the overall comments, a big issue with the
approach seems to be the semantics that can be associated with the
relations "similar-to" and "inverse-of" first mentioned in section 2.3
and whether these semantics fits the usage of these relations in the
relation mapping algorithms. Those relations are a mix of:
(1) relations defined by the designer of the model which may cover
very different semantics (e.g. a task "screw" may be considered as
similar to a task "glue" as both can be used to assemble a component,
but a task "screw" could also be considered as similar to "unscrew" as
both tasks use a screw driver!), and
(2) implication rules that allows the system to infer new pairs of
objects that satisfies the relation, based on structural knowledge
only.
As a result, it seems to be very hard to determine whether or not
those relations are really relevant for relation mapping. 

In the first sentence of section 5.1 on situated learning adaptation,
it is mentioned that the options for addressing the task are fairly
limited. This sounds inconsistent with the experimental results in
section 6.1 where pure Q-learning has a huge cost of execution,
precisely because the number of alternative options for addressing the
task is big.

In section 5.4, in the paragraph starting with "The top level task of
ADDAM is Disassemble", the example only mentions plan steps such as
"screw" which are related to "Assembly" tasks rather than
"Disassembly". I think the example should be reversed ;-)

The diagram in Figure 2 depicts a part of the TMKL model of ADDAM. At
which level of this task/methods hierarchy are situated the different
tasks that corresponds to an action (such as the execute-remove task
of Table 1)? Are they situated in a different task/method hierarchy
that corresponds the execution level whereas the diagram of Figure 2
corresponds to a meta-level?

In the end of section 5.4, on page 20, it is not precised exactly
when does REM make the two inserted mapping tasks optional. Is it in
step 1 (Make Plan Hierarchy) or in step 2 (Dependency Mapping) ? In
this case, this should be mentioned in the description of the adequate
step on pages 17-18, otherwise, the way it is described now may make
the reader think that because of the problem of non-idempotency of the
inversion, some kind of "work-around" was implemented afterward.

Given that there is no detail about the complexity analysis, I find
section 6.4 not very informative.

A few typos:

p29, l4: that that agents
p30, l11: an meta-reasoning agent

