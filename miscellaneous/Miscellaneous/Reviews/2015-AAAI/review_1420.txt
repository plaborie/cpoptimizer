<!--
  == For your convenience, this form can be processed by EasyChair
  == automatically. You can fill out this form offline and then upload it
  == to EasyChair. Several review forms can be uploaded simultaneously.
  == You can modify your reviews as many times as you want.
  == 
  == When filling out the review form please mind the following rules:
  == 
  == (1) Blocks such as this are comments. EasyChair will ignore them.
  ==     Do not write any text into these blocks as it will be ignored.
  ==     You can add comments to the review form or remove them.
  == (2) Write only into the tags where instructed. Do not modify any
  ==     tags and attributes, or the review will become unusable and will
  ==     be rejected by EasyChair.
  -->
<review id="1990843::954233"
        submission="1420"
        title="Algorithm Selection via Ranking"
        authors="(anonymous)"
        pc_member="Philippe Laborie">
<score id="264254" name="Significance of the Contribution">
<!--
  == Includes novelty in terms of questions addressed or solutions proposed
  == or impact potential on science or applications. 

  == Take a stance: try to avoid scores of + (slightly positive) and -
  == (slightly negative)..
  ==
  == Select your choice from the options below and write its number below,
  == before the </score> tag.
  ==
  == 10 +++++ (highly positive)
  == 9 ++++
  == 8 +++
  == 7 ++
  == 6 + (slightly positive)
  == 5 - (slightly negative)
  == 4 --
  == 3 ---
  == 2 ----
  == 1 ----- (highly negative)
  --> 7
  
</score>
<score id="264255" name="Soundness and Positioning with Respect to Related Work">
<!--
  == Also includes all other aspects of technical quality other than the
  == depth of the theoretical and experimental analysis. If references to
  == relevant related work are missing, please provide several complete
  == example references. 

  == Take a stance: try to avoid scores of + (slightly positive) and -
  == (slightly negative)..
  ==
  == Select your choice from the options below and write its number below,
  == before the </score> tag.
  ==
  == 10 +++++ (highly positive)
  == 9 ++++
  == 8 +++
  == 7 ++
  == 6 + (slightly positive)
  == 5 - (slightly negative)
  == 4 --
  == 3 ---
  == 2 ----
  == 1 ----- (highly negative)
  --> 7
  
</score>
<score id="264256" name="Depth of Theoretical and/or Experimental Analysis (as appropriate)">
<!--
  == Take a stance: try to avoid scores of + (slightly positive) and -
  == (slightly negative)..
  ==
  == Select your choice from the options below and write its number below,
  == before the </score> tag.
  ==
  == 10 +++++ (highly positive)
  == 9 ++++
  == 8 +++
  == 7 ++
  == 6 + (slightly positive)
  == 5 - (slightly negative)
  == 4 --
  == 3 ---
  == 2 ----
  == 1 ----- (highly negative)
  --> 8
  
</score>
<score id="264257" name="Quality of Presentation">
<!--
  == Take a stance: try to avoid scores of + (slightly positive) and -
  == (slightly negative)..
  ==
  == Select your choice from the options below and write its number below,
  == before the </score> tag.
  ==
  == 10 +++++ (highly positive)
  == 9 ++++
  == 8 +++
  == 7 ++
  == 6 + (slightly positive)
  == 5 - (slightly negative)
  == 4 --
  == 3 ---
  == 2 ----
  == 1 ----- (highly negative)
  --> 6
  
</score>
<score id="261216" name="SUMMARY RATING">
<!--
  == Scores from + to +++++ indicate that the submission could be accepted
  == (with either a poster presentation or a talk). The stronger your
  == feeling, the higher your score. Scores from - to - indicate that the
  == submission should be rejected. 

  == The summary rating does not need to be an "average" of the other
  == ratings. 

  == Take a stance: try to avoid scores of + (slightly positive) and -
  == (slightly negative)..
  ==
  == Select your choice from the options below and write its number below,
  == before the </score> tag.
  ==
  == 5 +++++ (highly positive)
  == 4 ++++
  == 3 +++
  == 2 ++
  == 1 + (slightly positive)
  == -1 - (slightly negative)
  == -2 --
  == -3 ---
  == -4 ----
  == -5 ----- (highly negative)
  --> 1
  
</score>
<score id="261217" name="REVIEWER'S CONFIDENCE">
<!--
  == Select your choice from the options below and write its number below,
  == before the </score> tag.
  ==
  == 3 I am certain of my scores
  == 2 I am somewhat certain of my scores
  == 1 I am uncertain of my scores
  --> 1
  
</score>
<score id="264258" name="Breadth of Interest to the AI Community">
<!--
  == Helps the SPC and PC chairs to decide the presentation format of the
  == submission, if accepted, or rule it out of scope of AAAI-15. 

  == Scores from + to +++++ indicate that the submission is in scope of
  == AAAI-15..
  ==
  == Select your choice from the options below and write its number below,
  == before the </score> tag.
  ==
  == 6 +++++ (almost all AAAI-15 participants will be interested)
  == 5 ++++
  == 4 +++
  == 3 ++
  == 2 + (only a very small number of AAAI-15 participants will be interested)
  == 1 - (no AAAI-15 participants will be interested; out of scope of AAAI-15)
  --> 4
  
</score>
<score id="264259" name="Easily Accessible Paper">
<!--
  == Helps the SPC and PC chairs to decide which papers to label as "easily
  == accessible" in the program. An easily accessible paper is one that
  == makes good reading material for people with a general background
  == knowledge of artificial intelligence but no detailed knowledge of the
  == subarea covered in the paper. 

  == Scores from + to +++++ indicate that the submission could be labeled
  == as "easily accessible" in the program. 

  == Take a stance: try to avoid scores of + (slightly positive) and -
  == (slightly negative)..
  ==
  == Select your choice from the options below and write its number below,
  == before the </score> tag.
  ==
  == 10 +++++ (highly positive)
  == 9 ++++
  == 8 +++
  == 7 ++
  == 6 + (slightly positive)
  == 5 - (slightly negative)
  == 4 --
  == 3 ---
  == 2 ----
  == 1 ----- (highly negative)
  --> 5
  
</score>
<text id="264262" name="Comments for the Authors">
<!--
  == The comments should address all criteria above. The purpose of the
  == comments is to explain your scores to the authors and PC members,
  == including the SPC and PC chairs (to enable the PC members to reach
  == consensus and the SPC and PC chairs to make more informed decisions
  == than just basing them on scores) but also to help the authors to
  == improve their submissions. Scores from - to - should be justified
  == especially carefully, as should the opinion that the submission is out
  == of scope of AAAI-15. AAAI has always been proud of the quality of the
  == reviews and the depth of the thoughts that the PC members put into
  == them. Typical reviews should be at least 400 words long but are often
  == longer than that. 

  == For resubmissions, comment on how well the authors have addressed the
  == issues brought up in the previous reviews. 

  == If needed, add questions for the authors (that you want them to
  == address in their author feedback) at the very end of your comments..
  -->

There are a few things that should be clarified in the paper:

- When introducing function f_{p,s}(\Theta) in "Polynomial Model", please, add a few words to say that this function denotes the preference score for a given pair (p,s). This may be evident but it is not explicitly said until the end of the description of the approach in the section "Prediction Phase". 

- In the end of the Ranking Desiderata section, you mention that only the solver pairs (s,s') such that s is one of the top K solvers is included in the training set. I do not understand which top K solvers you mean here. The top K solvers among which ones? The only answer I can come with is the top K solvers for solving the problem p. Does it mean that you take a subset of problems LP in P and for each problem p in LP, consider in the training set D all the triplets (p,s,s') where s is better than s' on p and s is among the K best solvers to solve p (this also suppose that you run all solvers on p) ? But it is not clear how this can be justified by the fact the approach is only interested in learning the top K solvers for a given problem. It seems to introduce some bias in the approach.

 Some more general and open questions:

- What one lose by only considering ranking (symbolical data) and not numerical data about the solvers performance in the learning data set? The proposed approach clearly throws some information away. For which reason do you think the proposed approach still seems to be competitive? Because it better exploits the ranking (more theoretically grounded method, good convergence of the SGD procedure) ? Or because the ranking captures most of the information about the relative performance of solvers?

- The experimental section is informative and really shows that RAS is competitive. The final remark suggest that the RAS approach is specifically more efficient than the RF baseline for small CPU times and this is particularly noticeable on the rand50S data set. This observation seems very difficult to explain as from my understanding, the RAS method only consider the final result of the solvers (at the CPU time limit) in the learning sets. Do you have some elements that could help interpreting this observation?

- I'm always a bit frustrated when reading most of the papers about algorithm selection and portfolio configuration. Being more from the side of people that develop solvers, I see that the large panel of ideas we develop result in more and more interesting and sophisticated (many parameters ...) solvers. This feeds the research domain on algorithm selection and portfolio configuration, which is very good. But I see few contributions that work the other way round, that is, aim at providing some deeper understanding of *why* solver A works better than solver B on a particular type of problem. In this context the proposed approach is interesting because for instance just looking at the coefficients vectors alpha_i, beta_i_i' one can quite directly see which solvers are weak for an instance feature p_i or a pair of instance features (p_i,p_i'). I think this type of information would be very useful for solver developers.

Some more details:

- In the algorithm, the best rank rmin on line 2 is not used anywhere. What is it used for? Also, it could be good to give, at least an idea of the time it takes for the learning in the experiments.


</text>
<text id="264263" name="Confidential Remarks for the Program Committee">
<!--
  == If you wish to add any remarks intended only for PC members, please
  == write them below. These remarks will only be seen by the PC members
  == having access to reviews for this submission. They will not be sent to
  == the authors. This field is optional. 

  == If you feel that that the potential significance of the submission is
  == so high that it should be accepted despite larger deficits in other
  == areas, explain your position here..
  -->






</text>
<text id="264264" name="Nomination for Best Paper or Best Student Paper">
<!--
  == If you want to nominate the submission for best paper or best student
  == paper, explain why. Otherwise, leave this box empty. If you do not see
  == information on EasyChair whether the primary author is a student,
  == nominate the submission for best student paper if, in your judgment,
  == the submission would be a candidate if the lead author were a student.
  == These remarks will only be seen by the PC members having access to
  == reviews for this submission. They will not be sent to the authors.
  == This field is optional..
  -->






</text>
<reviewer>
  <!--
    == If the review was written by (or with the help from) a subreviewer
    == different from the PC member in charge, add information about
    == the subreviewer below. Write subreviewer's first name, last name
    == and email between the tags below.
    -->
  <first_name>  </first_name>
  <last_name>   </last_name>
  <email>  </email>
</reviewer>
</review>
