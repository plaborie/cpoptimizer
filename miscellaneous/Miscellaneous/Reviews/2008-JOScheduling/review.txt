
========================================================================
Recommendation:

[ ] Accept as is
[ ] Needs minor revisions
[X] Needs major revisions
[ ] Reject

========================================================================
Reviewer Blind Comments to Author

The article defines and proposes algorithms to solve a robust
optimization problem based on a non-deterministic version of the
discrete time/cost problem with deadline (DTCP-D). The optimization
criterion is based on a discrete optimization approach proposed in
[Bertsimas&Sim 2003].

As far as I know, this problem is original and it is a good starting
point for integrating the notion of non-deterministic costs on this
type of projects. But I think the current model is still quite far
from the requirements of actual applications and this may be a problem
as an important focus of this special issue is on applications. For
instance, the proposed model investigates the compromise time/cost but
does not take resources into account (this is part of the future work)
and this compromise time/cost is only considered from the point of
view of a fixed makespan whereas, as mentioned by the authors in
section 2, in the context of BOT projects for instance, the objective
is to minimize a compromise between the project makespan and the
costs. In the proposed model, the makespan is supposed to be fixed. In
the context of this special issue, I think the paper could be improved
by giving more indications about how this work can be used/extended to
solve problems where the makespan is not fixed and may involve
resource limitations.

The description of the contribution of the paper and the comparison
with the state of the art is quite clear except that one could expect,
in the introduction, a bit more details about the continuous time-cost
trade-off problem (which seems to be close to the problem being
studied) and the recent approach of (Cohen et al, 2008) to solve it.

The justification for the introduction of model 2 (beginning of section
2.2.1) is not very clear. If an activity is not on the critical path
and have a large slack, then, probably a "not expensive" mode can be
chosen and one can expect that for "not expensive" modes, the
difference between the pessimistic cost and the expected cost is
smaller so the choice of a pessimistic or average assumption for this
type of activity (in the set gamma or not) will naturally have less
impact, even in model 1. Furthermore, I think that the reason why
model 2 is better on the time-based measures is that, because it
focuses on the impact of critical activities, it will tend to minimize
the number of critical activities as a non-critical activity will not
increase the part of the cost related with uncertainty management. But
in this case, if the objective really is to minimize the number of
critical activities one could better work directly on the minimization
of this criterion even by just considering the deterministic version
of the problem using expected mode costs. To summarize, neither the a
priori justification for model 2, nor the experimental results seem to
provide a clear support for this type of model. And, by the way, the
comparison of the robust models on table 1 does not help much
because for both models (as well as for both different values of
Gamma), the model combination (1,1,2,2) is always an optimal
solution. I think the argumentation for models 2 and 3 should be
improved and the small example modified.

The description of the algorithms should be more detailed:
 * In the description of the Benders decomposition approach, step 2 is
   well described but the other steps should be more detailed, in
   particular step 3.
 * The Tabu search approach is only highlighted. In a journal article,
   I think one would expect a more formal and complete description. In
   particular, except if reading between the lines, nothing is said
   about the different types of moves. Furthermore, nothing is said
   about how the fitness function is evaluated given a vector of
   mode. How is it done ? Is it computationally expensive?

The Benders decomposition and the Tabu search involve several
parameters (K, epsilon, xi, max number of GUB cups, tabu list
size). It would be interesting to have more details about how these
parameters values where chosen. A set of 30 pretests involving
problems with different sizes is mentioned. How these tests are
related with the ones used in the experimental evaluation?

Nothing is said about the size (number of activities) of the instances
used in the experimental evaluation (except for the problem in figure
2 with 85 activities). How the proposed algorithm scales with the
number of activities ? With the (average) number of possible modes for
each activity ?

I do not really understand Table 3:
 * What does the number of LP and of IP iterations represent ? 
 * Which approach is used to solve the deterministic version of the
   problem ? The same Benders decomposition with Gamma=0 ?
 * For the lines related with varying the CNC parameter in the case of
   robust scheduling, which value of Gamma is used ?

There is a paragraph about the effect of Gamma (p23,l54 until
p24-l20). Is this paragraph related with the results reported on some
table? 

To summarize, I think the problem studied in this paper is original,
represents a large amount of work and is a good starting point. The
article should be improved in a number of directions:
- improve justification for models 2 and 3
- give more details about the algorithms
- provide more information in the experimental section about how the
  proposed approach scales with problem size

A few more detailed comments:

p8, l19: pervious

p9: as CR depends on the mode assignment, I would suggest to denote
this set CR(x) in equation (3)

p10: which value of xi is used for determining the criticality of
activities in the example of table 1? Is it xi=0.25?

p13,l51: a new parameter K is introduced here. It should be renamed to
avoid confusion the K on formula 4 (number of extreme points of the
polytope).

p18: the concepts of concave/convex functions is mentioned here but
not clearly defined and never used. It could be removed I think.

p20, l18: 3 => Table 3

========================================================================
Reviewer Confidential Comments to Editor

I'm hesitating between a "Reject" and a "Needs major revisions". I
finally selected this last recommendation because I'm not really a
top-level expert in this type of robust optimization in project
scheduling. This is to say that I won't fight for having this article
accepted.
