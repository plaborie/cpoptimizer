This paper is an improvement over a recent paper of the authors. The
original results are improved in two directions:
1- speed-up of the algorithm
2- improve quality of the solution in case more time is available The
improvements in both directions are really good: about 10X speed-up
without sacrificing too much the quality for the first item and
scheduling 8% more tasks than the previous results for item 2.

The paper is well written and easy to understand although some
definitions seem to be missing, for instance, avail-dur_i (in section
Retraction Heuristics / Max-Flexibility) is defined in the original
paper but the definition was, I suppose, forgotten in the present
paper.

The definition of an "unassignable task" is not clear at all (page2,
col1, "For each unassignable task i, ..."). It seems to say that a
task i is not assignable if and only if all the scheduled tasks j of
higher priority (pri <= prj) are so that they use a potential resource
of task i and intersects the interval [est_i,lft_i], which does not
make much sense to me.

In the "Performance Results" section, the fact no improvement could be
made after 10 iterations does not say anything about the optimality of
the solution as the procedure may be stuck in some local optima.

Although the standard deviation for those experiments on table 2 seem
to be small enough, which seems to indicate that the randomization is
fairly robust, there is no doubt that (as suggested by the authors
themselves), nore trials should be done per problem instance.

In general, the results seem to show that it is the "randomizing"
effect more than the "iterative" effect that helps improving the
solution quality, which explains why the Iterative Deterministic
method is not so good as the randomized ones. Did you try running a
single iteration of, say the VBSS approach to see whether it behaves
better than the original non-stochastic method ? In the same order of
ideas, table 2 shows that the iterative (pure) random method is much
better than the Iterative Deterministic method, does it mean that the
retraction heuristics are not really useful once a good enough
solution has been found after the first iteration ?  Could you
elaborate a little bit more on the usefulness of the retraction
heuristics in this context.

Some typos:
p1,col1,Abstract: imporvements
p1,col1,Introduction: problem(Becker
p2,col1,Introduction: possible(Becker
p4,col1,Improving Task Swapping Performances: the the amount
p6,col2,Iterated Task-Swapping: heursitic
p7,col1,Biased-Stochastic Task retraction: stochasitically
p7,col1,Biased-Stochastic Task retraction: heursitic
p7,col2,Biased-Stochastic Task retraction: an an acceptance
p7,col2,Biased-Stochastic Task retraction: heursitic
p8,col1,Conclusion:revisted



