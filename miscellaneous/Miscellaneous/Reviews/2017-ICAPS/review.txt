__________________________________________________________________________________________
Evaluation

Significance (*). Does the paper contribute a major breakthrough or an incremental advance?
 3: substantial contribution or strong impact
*2: modest contribution or average impact
 1: minimal contribution or weak impact
 
Soundness (*). Is the technical development accurate?
 3: correct
 2: minor inconsistencies or small fixable errors
 1: major errors
 
Scholarship (*). Please provide a scholarship score.
 3: excellent coverage of related work
*2: relevant literature cited but could be expanded
 1: important related work missing, or mischaracterizes prior research
 
Clarity (*). Please provide a clarity score.
 3: well written
 2: mostly readable with some room for improvement
*1: hard to follow
 
Reproducibility (*). Please provide a reproducibility score.
 5: code and domains (whichever apply) are already publicly available
 4: authors promise to release code and domains (whichever apply)
 3: authors describe the implementation and domains in sufficient detail
 2: some details missing but still appears to be replicable with some effort
*1: difficult to reproduce because of missing detail
 
Overall evaluation (*). Please provide an overall score.
 3: strong accept
 2: accept
 1: weak accept
 -1: weak reject
*-2: reject
 -3: strong reject
 
Reviewer's confidence (*). Reviewer's confidence
 4: expert
 3: high
*2: medium
 1: low
 
Suitable for a demo? (*). Suitable for a demo?
 3: yes
 2: maybe
*1: no
 
Nominate for Best Paper Award (*). Nominate for Best Paper Award
 2: yes
*1: no
 
Nominate for Best Student Paper Award (if eligible) (*). Nominate for Best Student Paper Award (if eligible)
 2: yes
*1: no
 
 
__________________________________________________________________________________________
Additional scores

[Applications track ONLY]: Importance and novelty of the application (*). [Applications track ONLY]: Importance and novelty of the application
 6: N/A (not an Applications track paper)
 5: very significant - approach and/or application are new and important
 4: novel - approach and/or application are new but not so important
 3: moderate - moderate significance of approach and/or application
*2: marginal - parts of the application or approach are new
 1: none - similar approach to the same application has been used before

[Applications track ONLY]: Importance of planning/scheduling technology to the solution of the problem (*). [Applications track ONLY]: Importance of planning/scheduling technology to the solution of the problem
 5: N/A (not an Applications track paper)
 4: very important - essential to solving the problem
*3: moderately important - adds significant capabilities
 2: marginally important - improves usability, capabilities or performance
 1: not important - could be done without it

[Applications track ONLY] Maturity (*). [Applications track ONLY] Maturity.
 7: N/A (not an Applications track paper)
 6: study of the success, acceptance, impact and/or deficiencies of a fielded system
 5: fielded system
 4: mature system with testing on realistic problems
 3: early prototype system with testing on realistic problems
*2: early prototype system with testing on artificial data
 1: challenge problem

[Robotics track ONLY]: Balance of Robotics and Automated Planning and Scheduling (*). [Robotics track ONLY]: Balance of Robotics and Automated Planning and Scheduling
*6: N/A (not a Robotics track paper)
 5: excellent mix between the two fields
 4: good mix between the two fields
 3: fair mix between the two fields
 2: nothing Robotics specific, pure "classical" ICAPS paper
 1: nothing on Automated Planning, pure Robotics paper

[Robotics Track ONLY]: Evaluation on physical platforms/simulators (*). [Robotics Track ONLY]: Evaluation on physical platforms/simulators
*6: N/A (not a Robotics track paper)
 5: runs on real robots
 4: runs in a standard robot simulator (Gazebo, Morse etc.)
 3: could be used with a simulator or robot system
 2: still some work to have it running on robots
 1: cannot run on a real or simulated robot system in its current form

[Robotics Track ONLY]: Significance of the contribution (*). [Robotics Track ONLY]: Significance of the contribution
*6: N/A (not a Robotics track paper)
 5: significant in both Robotics and Planning
 4: significant in Planning (i.e. planning researchers would care about this paper)
 3: significant in Robotics (i.e. robotics researchers would care about this paper)
 2: marginally significant in one Robotics and/or Planning
 1: not significant

__________________________________________________________________________________________
Review


Review (*). Please provide a detailed review, including justification for your scores. This review will be sent to the authors unless the PC chairs decide not to do so.

The article describes a stochastic resource allocation problem in the domain of smart energy systems where computational power (in particular the RAM) is very limited. The authors propose a local search method to solve the problem and compare it to more computationally expensive methods like Mixed Integer Linear Programming.

The paper is hard to follow because it is lacking some formalism or, when formal definitions are involved, it is missing some important details and formal descriptions are not well linked together. For instance there is a general description of the problem in section "Stochastic Resource Allocation Problem" as an 8-uple but many of the elements described later on in this section do not clearly refer to the elements of this 8-uple: for instance the function f(G,D) seems related to the f_u but looks somewhat more general. I list some things that did not seem clear to me in the more detailed comments below.

From the application point of view, I think you should better describe how it is supposed to work in practice. In particular:
- How the user's requirements are supposed to be collected? How often? Is it on request of the users? Based on some periodical demands ? How do you get the parameters of the user's demands that are used as input of your approach?
- How would the policies generated by the system be transmitted and executed? Automatically by selecting which users are served, when and how, or would they be sent locally to each user ? 
I'm asking because without these answers, I do not see why users request are modeled as stochastic demands. Users express some preferences on their demand (preference on when to start the activity, on its duration) but if it is up to the system (through the output control policy) to decide when to start the activity and how long it should last, it looks like a deterministic demand with some objective function to maximize the user preference. Of course I understand that the energy availability is stochastic but as long as the demands are concerned this is much less clear. In fact these probability distributions on the demands seem to potentially describe 3 types of things:
1- some "classical" domains for decision variables (e.g. the user wants to have its activity start between 1PM and 3PM but does not really care when exactly)
2- some preference on some values (e.g. he prefers to start between 1PM and 3PM but, if needed he can start sooner or later even if it incurs some cost)
3- some uncertainties on the values (e.g. an activity to load an item will last between 2 and 3 hours depending on its estimated uncertain current load), but here one cannot really speak of "preference"
It is not clear what the probability distributions on the demands are supposed to represent.

The definition of the states handled in output control policies involves only two state variables: the battery charge b and the expected amount of solar energy E[G]. So, as mentioned in the paper, the state is global whereas the system generates a set of policies \pi_i, one for each user. As the state does not seem to contain any notion of time, I'm wondering how the policies allow to distribute the available energy over the users over time. For instance suppose a simple case with 8 users who posted the same request for, say 5W of power for a duration of 1h between 1PM and 8PM. If the battery is currently empty but assuming the amount of solar energy is 5W over the horizon (so that the requests can only be served one after the other), how would the 8 individual policies look like? My feeling is that here, the state does not really changes so I do not see how the policies would allow to sequence the 8 demand activities. There seem to be something missing in the description of states or in the description of policy execution. In general, I think it would help to give an example of policy produced by the approach on a toy example.


More detailed comments:

p2, col1: item defining G: why not just say that supp(G)=T ?

p2, col1: item defining set of resource-consuming activities A: while the definition of the problem "looks" formal here, you do not formally define the different types of probability distributions associated with an activity: you mention these distributions model different types of user's preferences (start time, resource quantity, later on in the paper you also mention activity duration). It seems to me that the semantics of these distributions is important for the definition of the problem so I think you should precisely distinguish them here.

p2, col2: a SAA is used to model f(G). It makes sense but it introduces an additional dimension in the size of the problem which is the number of scenarios. In your approach, you seem to project these scenarios on the MDP (see section Approximating Complex Scenarios as an MDP). But given that the state only contain two variables (see earlier comment), it seems that making a Markovian assumption is a very strong assumption here, in particular because one can expect some strong temporal correlation for the solar power generation profiles. Another argument against the Markovian assumption is the discretization itself. It would be necessary to discuss these assumptions.

p3, col2: if I understand well, the term c_1 in Eq 13 is a large enough factor so that constraints on critical activities are satisfied with the required probability. So the objective is lexicographical: first minimize penalty term for unserved critical activities, then maximize preference. Maybe it is better to state the objective this way, rather than introducing this artificial c_1 coefficient which is probably not very useful in your local search approach ?

p4, col1: the notations are not clear: M_\pi is a time-window and a_i seems to be an action realization, so what a_i \in M_\Pi formally means?

p5, col1: it is not clear how (and even "if") the reward defined here is related with the objective function of Eq 12-13.




Confidential remarks for the program committee. If you wish to add any remarks intended only for PC members, please write them below. These remarks will only be seen by the PC members having access to reviews for this submission. They will not be sent to the authors. This field is optional.

The paper is really hard to follow because of so many imprecisions all over the place. In the end, it is very possible that there is really some good contributions (on the modeling aspects, on the resolution with the interesting focus on limited computational power to solve the problem) but it would require some work to clean it up. The paper does not seem to me mature enough for acceptation. 


