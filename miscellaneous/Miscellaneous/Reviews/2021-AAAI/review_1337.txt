Paper ID:      1337
Paper Title:   An Intelligent Model for Solving Manpower Scheduling Problems

REVIEW QUESTIONS

1. [Summary] Please summarize the main claims/contributions of the paper in your own words. (Do not provide any review in this box)
*   (visible to authors during feedback, visible to authors after notification, visible to other reviewers, visible to meta-reviewers)

The paper describes a  metaheuristic approach to solve a problem in the context of manpower scheduling.


2. [Novelty] How novel is the paper?
*   (visible to authors during feedback, visible to authors after notification, visible to other reviewers, visible to meta-reviewers)
 [X] Main ideas of the paper are known or incremental advances over past work
 [ ] Paper contributes some new ideas
 [ ] Paper makes non-trivial advances over past work
 [ ] Main ideas of the paper are creative and distinctive


3. [Soundness] Is the paper technically sound?
*   (visible to authors during feedback, visible to authors after notification, visible to other reviewers, visible to meta-reviewers)
 [X] The paper has major technical flaws, necessitating another review after corrections
 [ ] The paper has minor technical flaws that are easily fixable
 [ ] I have not checked all details, but the paper appears to be technically sound
 [ ] I have carefully checked all details and did not find any technical flaw

4. [Impact] How important is the paper likely to be, considering both methodological contributions and impact on application areas? *   (visible to authors during feedback, visible to authors after notification, visible to other reviewers, visible to meta-reviewers)
 [ ] The paper is not relevant to the AAAI community
 [X] The paper will have low overall impact
 [ ] The paper will impact a moderate number of researchers
 [ ] The paper will have a broad and significant impact

5. [Clarity] Is the paper well-organized and clearly written? *   (visible to authors during feedback, visible to authors after notification, visible to other reviewers, visible to meta-reviewers)
 [X] Poor: paper is unclear and very hard to understand
 [ ] Fair: paper is somewhat clear, but important details are missing or confusing, which hurts readability
 [ ] Good: paper is well organized but language can be improved
 [ ] Excellent: paper is well organized and clearly written

6. [Evaluation] Are claims well supported by experimental results? *   (visible to authors during feedback, visible to authors after notification, visible to other reviewers, visible to meta-reviewers)
 [ ] Not applicable: This paper does not have experiments
 [X] Poor: The experimental design is flawed and unconvincing
 [ ] Moderate: Experimental results are weak: important baselines are missing, or improvements are not significant
 [ ] Good: Experimental results are sufficient, though more analysis would significantly add support to the claims
 [ ] Excellent: Experimental results are comprehensive and strongly support the claims

7. [Resources] How impactful will this work be via sharing datasets, code and/or other resources? (It may help to consult the paperâ€™s reproducibility checklist.) *   (visible to authors during feedback, visible to authors after notification, visible to other reviewers, visible to meta-reviewers)
 [ ] Not applicable: no shared resources
 [X] Poor: shared resources are not likely to be useful in future work
 [ ] Fair: some may find shared resources useful in future work
 [ ] Good: shared resources are likely to significantly impact future work

8. [Reproducibility] Would the experiments in the paper be easy to reproduce? (It may help to consult the paperâ€™s reproducibility checklist.) *   (visible to authors during feedback, visible to authors after notification, visible to other reviewers, visible to meta-reviewers)
 [ ] Not applicable: this research has no experimental component
 [X] Poor: e.g., experimental setup details are incomplete/unclear, and code/data are not available to aid reproducibility
 [ ] Meets Minimum Standard: e.g., code/data unavailable, but paper is clear enough that an expert could confidently reproduce
 [ ] Good: e.g., code/data available, but some details of experimental settings are missing/unclear
 [ ] Excellent: e.g., code/data available and paper comprehensively describes experimental settings

9. [Reasons to Accept] Please describe the paperâ€™s key strengths. *   (visible to authors during feedback, visible to authors after notification, visible to other reviewers, visible to meta-reviewers)




10. [Reasons to Reject] Please describe the paperâ€™s key weaknesses. *   (visible to authors during feedback, visible to authors after notification, visible to other reviewers, visible to meta-reviewers)

The paper is very difficult to read because it is lacking a crisp and formal description of the problem. Decision variables of the problem are never formally introduced:
- do we want to find a start time for the different jobs? what is the time granularity ... days, shifts, more precise?)
- how do the job express their requirement in terms of manpower ?
Overall, it seems that the problem is a fairly classical manpower scheduling problem.

The proposed GA is also missing many details so that it is not possible to understand its main principles.

The experiments are only performed on what seems to be a very small problem.


11. [Detailed Comments] Please provide other detailed comments and constructive feedback. *   (visible to authors during feedback, visible to authors after notification, visible to other reviewers, visible to meta-reviewers)

I think the paper should start with a complete and formal description of the problem.
In particular, what are the decision variables of the problem and what are the possible values for these variables.

The notations are particularly hard to understand.

For example: "We define the arbitrary jobs set K contains jobs that encoded as (1; 2; 3; ...; k).
For arbitrary job position K_j , to determine whether the employee i is on duty that day,
the employee of corresponding position can be coded as impact function \delta^{Kj}_i".

What is the position K_j of a job ? Is it not just the index "j" ?
Also "whether the employee i is on duty that day": which day ?
Do you have a variable in your model defining the day of a job ? Then you should explicitely describe this variable.

Also, there are some constraints \phi_{k_i}. Does the "k" here refer to some jobs ? It seems that not and it is very misleading.

"... which indicates that for employee i in any position K" What is the "position" of an employee ? In your notations, K denotes the set of all jobs ...

In section 4.1, you mention "optimal solutions". How do you prove that some solutions are optimal ?

In the experiments, the proposed approach seems to be compared with an Integer Programming model.
The IP model seems to be faster than the GA so I guess it stopped with a solution that was proved to be optimal.
In this case, how can it be that the "accuracy" of IP is only of 70% ? That do not really make sense.


12. [QUESTIONS FOR THE AUTHORS] Please provide questions for authors to address during the author feedback period. (Please number them) *   (visible to authors during feedback, visible to authors after notification, visible to other reviewers, visible to meta-reviewers)

Q1: What are the different decision variables of the problem and their domain ?

Q2: What do you mean by "optimal" solution in the experimental section ? How do you prove optimality of solutions ? Are you experimenting with a single problem instance ? What is the number of tasks in the problem ?


13. [Ethical Considerations] Please highlight any ethical considerations that must be considered before a final decision (it may help to consult the paperâ€™s ethics statement, if provided)   (visible to authors during feedback, visible to authors after notification, visible to other reviewers, visible to meta-reviewers)



14. [OVERALL SCORE]
*   (visible to authors during feedback, visible to authors after notification, visible to other reviewers, visible to meta-reviewers)
 [ ] 1 - Trivial, wrong, or known
 [ ] 2 - Strong reject: will fight to get it rejected
 [X] 3 - Clear reject
 [ ] 4 - Reject
 [ ] 5 - Below threshold of acceptance
 [ ] 6 - Above threshold of acceptance
 [ ] 7 - Accept
 [ ] 8 - Clear Accept (Top 50% accepted papers (est.))
 [ ] 9 - Accept: will fight to get it accepted
 [ ] 10 - Accept (Top 5%)

15. [CONFIDENCE] *   (visible to other reviewers, visible to meta-reviewers)
 [ ] Reviewer made an educated guess
 [ ] Reviewer is broadly knowledgeable, but not an expert in the area
 [X] Reviewer is knowledgeable in the area of the paper
 [ ] Reviewer is an expert in the specific topic of the paper

16. How many years have you worked in Artificial Intelligence research? *   (visible to other reviewers, visible to meta-reviewers)
 [ ] Less than 2 years
 [ ] 2 year
 [ ] 3 year
 [ ] 4 year
 [ ] 5 year
 [ ] 6-10 year
 [ ] 11-15 year
 [X] More than 15 years

17. [Award] Should this paper be considered for an outstanding paper award?   (visible to other reviewers, visible to meta-reviewers)
 [ ] Yes
 [X] No

18. Confidential comments to SPC, AC, and Program Chairs   (visible to meta-reviewers)






19. Please acknowledge that you have read the author rebuttal. If your opinion has changed, please summarize the main reasons below.   (visible to authors after notification, visible to other reviewers, visible to meta-reviewers)
