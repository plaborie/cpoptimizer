First of all we thank all the reviewers for the useful comments received. 
Our responses are interleaved in CAPITAL LETTERS in the following text, which 
merges the three paper's reviews. 

--------------------------------------------------------------
*** SUBMISSION NUMBER:	165
*** TITLE:     		Solving Resource-Constrained Project 
                        Scheduling Problems with Time-Windows 
                        Using Iterative Improvement Algorithms
*** AUTHORS:            (anonymous) 
--- CATEGORY:           Short Paper
*** PC MEMBER:	REV-A
--------------------------------------------------------------
*** REVIEW:

---  your scores. This review will be sent to the authors unless
---  the PC chairs decide not to do so. This field is required.

Relevance -  Is the work relevant to the call for papers?

Yes - highly relevant

Significance - To what extent are the ideas and contributions of the  
paper novel and important to planning and scheduling theory or practice?

The paper presents results of an experimental study of an existing
algorithm, Iterative Flattening Search (IFS) , on the Resource
Constrained Project Scheduling Problems (RCPSP) with maximal time
lags(RCPSP/max). A number of previous papers have discussed the IFS
algorithm on the pure RCPSP (without maximum time lags). Since the
algorithm has been modified very little (if at all), the paper
presents an incremental contribution.  It is interesting to see that
IFS can work well on problems where finding even a feasible solution
is not always trivial.

The experimental results look interesting and significant. Some of the
PSPLIB problems used in the study can be quite difficult to solve
using pure CP methods.

Technical quality - Is the work technically sound? Are the analyses,  
algorithms, theorems and proofs correct? Are the paper's claims argued/ 
supported convincingly? Is the empirical evaluation convincing?

Some details are missing from the paper, and there is not sufficient
information given to reproduce the exact IFS algorithm that is
used. 

WE ARE SORRY. GIVEN THE SHORT ROOM AVAILABLE (4 PAGES) WE FOCUSSED MORE ON 
THE EXPERIMENTAL RESULTS ON RCPSP/MAX PROBLEMS AND LESS ON THE ALGORITHMIC 
PART, WHERE WE RELIED MORE ON THE REFERENCED PAPERS.

It is stated that in the flattening phase of IFS precedence
constraints are posted between activities in a minimal conflict
set. However there is no reference to or description of how these
constraints are identified (there are at least 2 ways of doing this in
the research literature). It is also stated that resource constraint
propagation is used in the flattening phase. I would like to know
which resource constraint filtering algorithms are being used.

THE CONSTRAINTS ARE IDENTIFIED ACCORDING TO THE ALGORITHM "ESTA" DESCRIBED IN THE
PAPER [CESTA ETAL 2002] LISTED IN THE SECTION REFERENCES. IN CASE OF
RCPSP/MAX PROBLEMS WE USE ONLY TEMPORAL CONSTRAINT PROPAGATION ALGORITHMS FOR
STP NETWORKS.

With maximal lags I believe the IFS algorithm can reach states in the
search which are infeasible i.e. no more precedence constraints can be
posted to resolve a minimal critical set.  It is not clear what the
IFS algorithm does in this case - is the search restarted from the
beginning or is the usual IFS relaxation step applied?

IN CASE OF FAILURE WITHIN THE IFS CYCLE, THE ALGORITHM RESUMES FROM THE
BEST SOLUTION FOUND SO FAR.

It is not stated how the initial solution is generated. Since the
authors state that the feasibility version of the RCPSP/max problem is
is NP-hard (shouldn't this be NP-complete), it would be good to know
this.

THE INITIAL SOLUTION IS GENERATED BY THE SAME PROCEDURE USED WITHIN THE 
IFS CYCLE. IN THIS CASE THE PROCEDURE STARTS FROM SCRATCH (EMPTY SOLUTION) WITH A 
"LARGE" HORIZON CONSTRAINT - IN THIS CASE 5 TIMES THE MAKESPAN OF THE INFINITE CAPACITY SOLUTION, 
THAT IS THE MAKESPAN OF THE SOLUTION WHERE RESOURCE CONSTRAINTS ARE RELAXED.

Quality of presentation - Is the paper clearly written? Is it well-
organized? Is the motivation for the research or the innovation of the
application well explained?

The paper is quite clearly written, although missing some details.
Given that this is a short paper submission this may be OK, but I
would prefer to see more detail on the algorithmic approach used.

There are some minor typos.

Suitability to AIJ - Should an extended version of this paper be  
solicited for submission to Artificial Intelligence Journal?

No.

--------------------------------------------------------------
*** SUBMISSION NUMBER:	165
*** TITLE:     		Solving Resource-Constrained Project 
                        Scheduling Problems with Time-Windows 
                        Using Iterative Improvement Algorithms
*** AUTHORS:            (anonymous) 
--- CATEGORY:           Short Paper
*** PC MEMBER:	REV-B
--------------------------------------------------------------

bol $\approx$ not appropriate in a sentence
	p3c1 sentence "The previous ... procedure." unclear 
Conclusion and Future Work:
	c2 "a hard", "a higher"
	l-1 "from"
	

Relevance -  Is the work relevant to the call for papers?
	Relevant according to the point "Analytic and empirical studies of planning and scheduling problems and algorithms for solving them" in the CfP
Significance - To what extent are the ideas and contributions of the paper novel and important to planning and scheduling theory or practice?
	Closure of several large-sized instances of the literature
Technical quality - Is the work technically sound? Are the analyses, algorithms, theorems and proofs correct? Are the paper's claims argued/supported convincingly? Is the empirical evaluation convincing?
	The empirical analysis is convincing.
Quality of presentation - Is the paper clearly written? Is it well-organized? Is the motivation for the research or the innovation of the application well explained?
	Could be reorganized as mentioned above.
Suitability to AIJ - Should an extended version of this paper be solicited for submission to Artificial Intelligence Journal?
	No sufficient theoretical contribution, no tuning of the existing method


--------------------------------------------------------------
*** SUBMISSION NUMBER:
*** TITLE:
*** AUTHORS: (anonymous)
--- CATEGORY:
*** PC MEMBER: rev-C
--------------------------------------------------------------
*** REVIEW:
---  Please provide a detailed review, including justification for
---  your scores. This review will be sent to the authors unless
---  the PC chairs decide not to do so. This field is required.

Relevance -  Is the work relevant to the call for papers?

The work is relevant to the call for papers; it presents an iterative improvement
approach based on Iterative Flattening Search for solving the RCPSP/max problem.

Significance - To what extent are the ideas and contributions of the  
paper novel and important to planning and scheduling theory or practice?

The main contribution of the paper is that by applying an existing algorithm (IFS)
to benchmark RCPSP/max problems, new best known values (upper bounds) are produced, and even three
optimal valued solutions (makespan equal to the lower bound) are found. 
The paper also studies the impact of the parameter values
for the relaxation step in IFS on the algorithm performance; based on the analysis as performed
for a set of smaller (30 task) benchmark problems, the best values are selected and used to solve another set of bigger (200 task) benchmark problems.

Technical quality - Is the work technically sound? Are the analyses,  
algorithms, theorems and proofs correct? Are the paper's claims argued/ 
supported convincingly? Is the empirical evaluation convincing?

For a short paper, the paper seems technically sound, even though certain details
are omitted (see below).
The empirical evaluation shows that the proposed approach performs well for the RCPSP/max
instances: it found three new optimal
solutions for the UBO200 set and improved over 27 currently best known results.

Quality of presentation - Is the paper clearly written? Is it well- organized? Is the motivation for the research or the innovation of the  
application well explained?

The paper is clearly written, with some exceptions. Some details are omitted.  

IFS should be at least described

PLEASE, SEE THE RESPONSE ABOVE.

It is  not clear to me what the number n_r represents (IFS-CP):
what are the individual relaxation attempts, in particular what does
"individual" refer to?

IFS-CP RELAXES THE CRITICAL PATH OF THE CURRENT SOLUTION. IN PARTICULAR,
N_R REPRESENTS THE NUMBER OF RELAXATION STEPS OPERATED ON THE CRITICAL PATH.
EACH STEP (1) REMOVES AT RANDOM (WITH PROBABILITY P_R) A SET OF PRECEDENCE CONSTRAINTS INCLUDED
IN THE CURRENT CRITICAL PATH AND (2) RE-COMPUTES THE CRITICAL PATH.

In Table 1, the best n_r parameter value is said to be approx. 6 or 7.
It is rather difficult to see this, maybe a little bit more should be said
about the metrics that are most important when deciding which n_r value
is better. For example, for n_r of value 5, the average CPU time and the
average IFS cycles are much smaller and pretty close to the ones for
n_r 7 respectively, the number of improved makespans is the same 
and the difference between the deltas for makespan is pretty small
(but possibly significantly smaller for 7).

THE MOST IMPORTANT METRIC IS DELTA_MK.

It is also not clear what is the delta makespan 8.91 "for the currently published
best solutions". Are the mk_i^0 values lower bounds as opposed to the current best known values
(upper bounds)?

THE VALUE 8.91 IS THE AVERAGE MAKESPAN GAP DELAT_MK CALCULATED FOR THE BENCHMARK J30 ON THE SOLUTIONS 
PUBLISHED ON THE WEB SITE CITED IN THE SECTION "EXPERIMENTAL ANALYSIS".

It should be clearly stated how many times each algorithms was run for each instance,
and what is 9.88 for IFS-CP (the average delta makespan for a certain n_r? which n_r?).
It is not clear to me how the values in the Best rows (Table 1) were computed.

THE ALGORITHM IFS-CP WAS RUN 7 TIMES ACCORDING TO THE 7 DIFFERENT VALUES OF THE PARAMETER 
N_R = 2,3,4,5,6,7,8.  THE VALUE 9.88 IS THE AVERAGE MAKESPAN GAP FOR THE BEST SOLUTIONS OBTAINED 
OVER THE PREVIOUS 7 RUNS.

THE VALUE 9.02 IS OBTAINED IN ANALOGOUS WAY FOR THE 7 RUNS OF THE ALGORITHM IFS-CH. 

THE VALUE 8.90  IS THE AVERAGE MAKESPAN GAP FOR THE BEST SOLUTIONS OBTAINED OVER THE 
PREVIOUS FULL SET OF 14 RUNS.

The performance of IFS-CH(100) is not shown in Table 1. The hypothesis 
that there always exists a value of p_r that improves over the full iterative sampling
procedure sounds plausible, but it is difficult to see that this is the case
based on just the results in Table 1.

Suitability to AIJ - Should an extended version of this paper be  
solicited for submission to Artificial Intelligence Journal?

This is a short paper, there is not enough material in it to decide if an extended version should be solicited for submission to AIJ.
