
<<Zak, Maud>>

 

1: Décrire la différence entre approche réaliste et approche utilitariste dans la démarche scientifique.


L’approche réaliste affirme qu’une théorie scientifique acceptée et consolidée décrit exactement comment les choses se passent dans le monde et permet d’appréhender la complexité en cherchant à comprendre ce qui fonctionne, pour qui, et dans quel contexte. 

(https://fr.wikipedia.org/wiki/Réalisme_scientifique)


À l’inverse, l’approche utilitariste est compatible avec l’appréhension des problèmes complexes par le biomimétisme. Les modèles de la pensée humaine sont construit avec des métaphores, des interprétations: nous ne sommes pas dans le cas d’une description exacte.


 

2: programmation logique/chainage avant

Dans un langage à base de règles simple en chaînage avant (on appelle cela un système de production) on a le programme:

 

var input[]=[], result[]=[], i=1, tmp=0;

 

when input.length>0 and i >= input.length then result.append(input[tmp]), input.removeAt(tmp), i=1, tmp=0;

when input[i] < input[tmp] then tmp=i, i=i+1;

when input[i] >= input[tmp] then i=i+1;

 

Lorsque l'instruction input=[2,0,5,4,9]; est exécutée, que contiendront les variables result et input en retour? Expliquer l'algorithme. Donner sa complexité.


On obtient en retour result=[0,2,4,5,0] et input=[]. L’algorithme range la suite du tableau input par ordre croissant en utilisant un tri par insertion: les valeurs sont insérées les unes après les autres dans une liste triée (initialement vide). 


La complexité des algorithmes de tri par insertion est O(n^2).

 

3: Smart City: Trouver sur internet 3 logiciels commerciaux professionnels destinés à remplir un rôle similaire à celui du projet SmartDeliveries. En vous basant sur la présentation commerciale, identifiez leurs principales caractéristiques démarquantes (quelles fonctionnalités mettent-ils particulièrement en avant par rapport à la concurrence). Fournir les références utilisées.


Nous pouvons citer les 3 logiciels suivants:

AnyLogig est présenté comme le leader des technologies de simulation pour les applications professionnelles. Il propose “le contrôle stratégique et opérationnel de la transportation et de la flotte basé sur la surveillance de données en temps réel, sur l’accumulation de statistiques, et des prévisions basées sur la simulation”. Il fournit entre autres une bibliothèque du trafic routier.

 (https://www.anylogic.fr/road-traffic/)


Citilog “crée une mobilité plus intelligente grâce à l'analyse vidéo et à l'intelligence artificielle appliquées aux solutions de gestion du trafic”. Ils promettent “un voyage plus fluide et plus sûr pour des millions de conducteurs à travers le monde”, avec une réduction des coûts et des risques pour les opérateurs de trafic. 

(https://www.citilog.com) 


C-The Difference apporte des services STI-C (Systèmes de Transports Intelligents Coopératifs) avec pour objectif de “combler le vide qui sépare les implémentations les plus avancées des STI-C dans un environnement urbain et les déploiements et opérations à plus grande échelle en ciblant les professionnels responsables des opérations et de la planification des transports urbains, les décideurs politiques et les décisionnaires finaux.”

(https://www.neogls.com/innovation/c-the-difference/)


 

4: trafic routier

a- Quelles sont les principales variables mesurées par un détecteur de trafic?

b-Qu'est ce que le diagramme fondamental d'un détecteur de trafic, pourquoi est-il utile pour mesurer et prévoir la congestion?

c- quel est le débit typique maximal d'un tronçon à une voie
•en zone urbaine


•sur voie rapide ou autoroute


•Pourquoi cette différence?



a)
Les principales variables sont:
- Le débit: mesurable par des dispositifs de comptage fixes.
- La vitesse
- Le taux d’occupation: pourcentage de temps durant lequel un point de la route est « occupé » par un véhicule au-dessus de lui. Il est à noter que sa qualité de mesure par des capteurs classiques est très dégradée lorsque les vitesses des véhicules sont basses: sur les réseaux urbains, avec des situations très congestionnées, les valeurs d’occupation sont trop changeantes pour être directement exploitables. 

b)
Le diagramme fondamental représente l’évolution de la vitesse du trafic en fonction du débit. Il permet de comprendre le fonctionnement d’une section ou d’un réseau routier et de déduire des paramètres de fonctionnement de la section, comme la vitesse libre ou la capacité.

Il peut être utilisé pour calculer automatiquement un seuil d'encombrement pour chaque détecteur et donc pour mesurer et prévoir la congestion.



5: temps de parcours

a) Quelles sont les principales variables prédictives du temps de parcours d'un camion de livraison en ville, par ordre d'importance décroissante? (déterminées en cours)

•Durée


•Heure 


•Jour de la semaine


•Origine (x, y)


•Destination (x, y)


•Catégories de routes, nb voies


•Durée statique


•Distance (vol d’oiseau)


•Id mission


•Durée estimée avec les règles



 

b) Citer 2 facteurs potentiels affectant les temps de parcours et difficiles à mesurer avec les données fournies dans les fichiers fournis en TP.

•Expérience du conducteur


•Motivation du conducteur (s’il doit se dépêcher…)


•Circonstances locales



 

6. Prescriptive Analytics

Les affirmations suivantes sont-elles vraies ou fausses:

 

a- Un problème de décision est dans la classe de complexité NP si et seulement si il n'existe pas d'algorithme polynomial pour le résoudre.

 

b- Dans l'industrie, la majorité des problèmes d'ordonnancement sont résolus grâce à des heuristiques.

 

c- Le problème suivant possède exactement trois solutions:

   u in {1,3}

   v in {1,2}

   w in {3,4}

   x in {1,5}

   y in {4,5}

   allDifferent(u,v,w,x,y)

 

d- L'algorithme de résolution de CP-Optimizer est un algorithme exact: si un problème d'optimisation est faisable, il garantit de trouver une solution optimale.

a.FAUX



Un problème NP est un problème de décision vérifiant les propriétés suivantes :
•Il est possible de vérifier une solution efficacement (en temps polynomial) ; la classe des problèmes vérifiant cette propriété est notée NP


•Tous les problèmes de la classe NP se ramènent à celui-ci via une réduction polynomiale ; cela signifie que le problème est au moins aussi difficile que tous les autres problèmes de la classe NP.



De plus, une propriété de la définition implique que s'il existe un algorithme polynomial pour résoudre un quelconque des problèmes NP-complets, alors tous les problèmes de la classe NP peuvent être résolus en temps polynomial. 

b./


c. FAUX il y a  1 seule solution: u=1 v=2 w=3 Y=4 x=5 




 

7. optimisation

 

a- En cherchant sur internet, décrivez un problème d'optimisation combinatoire non vu dans le cours dont la version de décision est un problème NP-Complet.

 

b- Décrivez une petite instance particulière de ce problème d'optimisation (avec des valeurs pour chacune des données).

 

c- Donnez une solution faisable non-optimale et une solution optimale de cette petite instance.

 

/

 

8. programmation par contraintes

 

Deux principes fondamentaux de la Programmation par Contraintes sont (1) la recherche arborescente et (2) le filtrage du domaine des variables. Décrivez brièvement ces principes, leurs rôles et la façon dont ils sont mis en oeuvre durant la résolution.

 

 

Dans le cadre de la programmation par contraintes, les problèmes sont modélisés à l'aide de variables de décision et de contraintes, où une contrainte est une relation entre une ou plusieurs variables qui limite les valeurs que peuvent prendre simultanément chacune des variables liées par la contrainte.
1.Recherche d’arborescence:



Dans le cas de la résolution sur domaines finis, il est en théorie possible d'énumérer toutes les possibilités et de vérifier si elles violent ou non les contraintes. C’est la méthode Générer et Tester: on génère toutes les affectations possibles et on vérifie si elles correspondent à des solutions. Cependant, cela s'avère impraticable pour des problèmes de taille moyenne en raison du grand nombre de combinaisons possibles.

2.Filtrage 



Une des principales parties de la résolution, appelée « filtrage », a pour but d'éviter cette énumération exhaustive. Elle consiste à déduire à partir des contraintes les valeurs impossibles. Lorsqu'une variable ne possède plus qu'un candidat, celle-ci est instanciée.

Dès qu’une variable est affectée on essaye de filtrer les valeurs pour les autres variables: on remplace la variable par sa valeur dans toutes les contraintes. On peut filtrer si une contrainte ne contient plus qu’une variable.


Cependant, le filtrage seul ne permet pas d'instancier toutes les variables, et il est donc nécessaire de scinder le problème en plusieurs parties (par exemple en instanciant une variable à chacune de ses valeurs possibles) et relancer le filtrage sur l'une de ces parties et ce, de manière récursive jusqu'à obtenir l'instanciation de toutes les variables. 












Maud ZAK













Élève-ingénieure en troisième année LinkedIn

École Nationale Supérieure de Cognitique (ENSC)